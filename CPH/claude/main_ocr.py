#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
OCR structurÃ© + Analyse juridique (Ollama/RunPod) - VERSION COMPLÃˆTE v7.1-FALKON-FIXED
Support PDF (OCR avec cache) et TXT avec anonymisation - Interface dual files avec Falkon
Author: Assistant Claude
Version: 7.1-FALKON-FIXED - ModifiÃ© pour utiliser le navigateur Falkon avec corrections lambda
Date: 2025-01-04
Modifications: Interface dual files, analyse comparative unique, lancement automatique Falkon
"""

import os
import sys
import argparse
import traceback
import subprocess
import time

# Import des modules
from config import check_dependencies, PROMPT_STORE_DIR
from ai_providers import get_ollama_models
from gradio_interface import build_ui

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def launch_falkon(url, delay=3):
    """Lance Falkon avec l'URL de l'application."""
    try:
        print(f"ğŸ¦… Lancement de Falkon dans {delay}s...")
        time.sleep(delay)  # Laisser le temps au serveur de dÃ©marrer
        
        # VÃ©rifier si Falkon est disponible
        result = subprocess.run(['which', 'falkon'], capture_output=True, text=True)
        if result.returncode != 0:
            print("âŒ Falkon n'est pas installÃ© ou disponible dans le PATH")
            print("ğŸ’¡ Installez Falkon avec : sudo apt install falkon (Ubuntu/Debian)")
            print(f"ğŸ“± Vous pouvez ouvrir manuellement : {url}")
            return False
        
        # Lancer Falkon
        subprocess.run(['falkon', url], check=False)
        print(f"âœ… Falkon lancÃ© avec : {url}")
        return True
        
    except Exception as e:
        print(f"âŒ Erreur lors du lancement de Falkon : {e}")
        print(f"ğŸ“± Ouvrez manuellement : {url}")
        return False

def main():
    """Point d'entrÃ©e principal du programme."""
    parser = argparse.ArgumentParser(description="OCR + Analyse juridique avec Ollama/RunPod (PDF/TXT + Anonymisation) - Interface dual files avec Falkon")
    parser.add_argument('--list-models', action='store_true', help='Lister les modÃ¨les Ollama disponibles')
    parser.add_argument('--ollama-url', default='http://localhost:11434', help='URL du serveur Ollama')
    parser.add_argument('--host', default='127.0.0.1', help='Adresse d\'Ã©coute (dÃ©faut: 127.0.0.1)')
    parser.add_argument('--port', type=int, default=7860, help='Port d\'Ã©coute (dÃ©faut: 7860)')
    parser.add_argument('--no-browser', action='store_true', help='Ne pas lancer Falkon automatiquement')
    parser.add_argument('--debug', action='store_true', help='Mode debug avec plus d\'informations')
    
    args = parser.parse_args()
    
    # Mode debug
    if args.debug:
        print("ğŸ” Mode debug activÃ©")
        print(f"ğŸ Python: {sys.version}")
        print(f"ğŸ“ RÃ©pertoire courant: {os.getcwd()}")
        print(f"ğŸ”§ Arguments: {args}")
    
    # VÃ©rification des dÃ©pendances
    print("ğŸ” VÃ©rification des dÃ©pendances...")
    try:
        check_dependencies()
        print("âœ… DÃ©pendances OK")
    except Exception as e:
        print(f"âŒ Erreur dÃ©pendances: {e}")
        return 1
    
    if args.list_models:
        print("ğŸ¤– ModÃ¨les Ollama disponibles:")
        try:
            models = get_ollama_models(args.ollama_url)
            for i, model in enumerate(models, 1):
                print(f"  {i}. {model}")
        except Exception as e:
            print(f"âŒ Erreur rÃ©cupÃ©ration modÃ¨les: {e}")
        return 0
    
    print("ğŸš€ DÃ©marrage de l'interface OCR Juridique...")
    print(f"ğŸ“ RÃ©pertoire des prompts : {PROMPT_STORE_DIR}")
    print(f"ğŸ¦… Navigateur configurÃ© : Falkon")
    
    # CrÃ©er le rÃ©pertoire des prompts si nÃ©cessaire
    if not os.path.exists(PROMPT_STORE_DIR):
        try:
            os.makedirs(PROMPT_STORE_DIR, exist_ok=True)
            print(f"ğŸ“ RÃ©pertoire crÃ©Ã© : {PROMPT_STORE_DIR}")
        except Exception as e:
            print(f"âš ï¸ Impossible de crÃ©er le rÃ©pertoire des prompts : {e}")
    
    try:
        print("ğŸ¤– Chargement des modÃ¨les Ollama...")
        models = get_ollama_models(args.ollama_url)
        print(f"âœ… {len(models)} modÃ¨le(s) disponible(s)")
        if args.debug:
            for model in models[:3]:  # Afficher les 3 premiers
                print(f"  - {model}")
        
        print("ğŸ—ï¸ Construction de l'interface...")
        app = build_ui()
        print("âœ… Interface construite")
        
        # Configuration du lancement
        launch_kwargs = {
            'server_name': args.host,
            'share': False,
            'inbrowser': False,  # DÃ©sactiver l'ouverture automatique du navigateur par dÃ©faut
            'show_error': True,
            'quiet': not args.debug,
            'server_port': args.port
        }
        
        # Construire l'URL
        url = f"http://{args.host}:{args.port}"
        
        print(f"ğŸ“¡ Serveur en cours de dÃ©marrage sur : {url}")
        
        # Lancer Falkon en arriÃ¨re-plan si demandÃ©
        if not args.no_browser:
            import threading
            falkon_thread = threading.Thread(target=launch_falkon, args=(url, 4))
            falkon_thread.daemon = True
            falkon_thread.start()
        else:
            print(f"ğŸ“± Pour ouvrir dans Falkon : falkon {url}")
            print(f"ğŸ“± Ou dans votre navigateur : {url}")
        
        print("ğŸ¯ Lancement de l'application Gradio...")
        
        # Lancer l'application Gradio
        app.launch(**launch_kwargs)
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ArrÃªt demandÃ© par l'utilisateur")
        return 0
    except Exception as e:
        print(f"âŒ Erreur lors du dÃ©marrage : {e}")
        if args.debug:
            traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
