#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Interface utilisateur Gradio pour OCR Juridique - Version Hybride CORRIG√âE
Version: 8.2-HYBRIDE-FIXED-CONSERVATIVE
Date: 2025-09-15
Fonctionnalit√©s: Mode hybride 3 √©tapes + arr√™t auto pod + corrections minimales
"""

import os
import gradio as gr
from datetime import datetime
import json
import threading
import time
import requests

# ========================================
# IMPORTS DES MODULES R√âELS
# ========================================

try:
    from hybrid_analyzer import (
        create_hybrid_analyzer, 
        SUPPORTED_DOMAINS, 
        SYNTHESIS_TYPES
    )
    from ai_wrapper import ai_call_wrapper, test_ai_connection, validate_ai_params
    from processing_pipeline import process_file_to_text
    from config_manager import load_ollama_config, save_url_on_change
    HYBRID_AVAILABLE = True
    print("‚úÖ Modules hybrides charg√©s avec succ√®s")
except ImportError as e:
    print(f"‚ö†Ô∏è Mode hybride non disponible: {e}")
    HYBRID_AVAILABLE = False
    # Fallback pour √©viter les erreurs
    SUPPORTED_DOMAINS = {"Aucun": "Aucun domaine"}
    SYNTHESIS_TYPES = {"synthese_executive": "Synth√®se ex√©cutive"}

# ========================================
# GESTION ARR√äT AUTOMATIQUE RUNPOD
# ========================================

class RunPodManager:
    """Gestionnaire pour l'arr√™t automatique des pods RunPod."""
    
    def __init__(self):
        self.last_activity = time.time()
        self.auto_stop_enabled = False
        self.timeout_minutes = 15  # Arr√™t apr√®s 15 min d'inactivit√©
        self.pod_id = None
        self.api_key = None
        self.monitor_thread = None
        
    def update_activity(self):
        """Met √† jour le timestamp de derni√®re activit√©."""
        self.last_activity = time.time()
        
    def configure_auto_stop(self, endpoint, token, timeout_minutes=15):
        """Configure l'arr√™t automatique."""
        try:
            # Extraction du pod ID depuis l'endpoint
            if "runpod" in endpoint and token:
                self.pod_id = self._extract_pod_id(endpoint)
                self.api_key = token
                self.timeout_minutes = timeout_minutes
                self.auto_stop_enabled = True
                
                # D√©marrer le monitoring
                if not self.monitor_thread or not self.monitor_thread.is_alive():
                    self.monitor_thread = threading.Thread(target=self._monitor_activity, daemon=True)
                    self.monitor_thread.start()
                
                return f"Arr√™t auto configur√©: {timeout_minutes}min d'inactivit√©"
            else:
                return "Configuration arr√™t auto √©chou√©e"
        except Exception as e:
            return f"Erreur config arr√™t auto: {str(e)}"
    
    def _extract_pod_id(self, endpoint):
        """Extrait l'ID du pod depuis l'endpoint."""
        try:
            # Format typique: https://xxx-runpod-id.runpod.net/
            if "runpod" in endpoint:
                parts = endpoint.split("//")[1].split(".")[0].split("-")
                return parts[-1] if len(parts) > 1 else None
        except:
            pass
        return None
    
    def _monitor_activity(self):
        """Thread de monitoring de l'activit√©."""
        while self.auto_stop_enabled:
            try:
                time.sleep(60)  # V√©rification chaque minute
                
                if self.auto_stop_enabled and self.pod_id and self.api_key:
                    inactive_time = (time.time() - self.last_activity) / 60
                    
                    if inactive_time > self.timeout_minutes:
                        print(f"Inactivit√© d√©tect√©e: {inactive_time:.1f}min")
                        self._stop_pod()
                        break
                        
            except Exception as e:
                print(f"Erreur monitoring RunPod: {e}")
                break
    
    def _stop_pod(self):
        """Arr√™te le pod RunPod."""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            url = f"https://api.runpod.ai/v2/{self.pod_id}/terminate"
            response = requests.post(url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                print(f"Pod {self.pod_id} arr√™t√© automatiquement")
                self.auto_stop_enabled = False
            else:
                print(f"√âchec arr√™t pod: {response.status_code}")
                
        except Exception as e:
            print(f"Erreur arr√™t pod: {e}")
    
    def disable_auto_stop(self):
        """D√©sactive l'arr√™t automatique."""
        self.auto_stop_enabled = False
        return "Arr√™t automatique d√©sactiv√©"

# Instance globale du gestionnaire
runpod_manager = RunPodManager()

# ========================================
# CONFIGURATION GLOBALE
# ========================================

DEFAULT_CONFIG = {
    "provider": "Ollama local",
    "chunk_size": 3000,
    "chunk_overlap": 200,
    "ollama_url": "http://localhost:11434"
}

app_state = {
    "current_provider": "Ollama local",
    "ollama_url": "http://localhost:11434",
    "models_list": ["mistral:7b", "mixtral:8x7b", "llama3.1:8b"],
    "hybrid_analyzer": None,
    "ready": HYBRID_AVAILABLE
}

# Prompts juridiques de base
FALLBACK_PROMPTS = {
    "Analyse juridique hybride": """Analysez ce document juridique de mani√®re approfondie :

1. IDENTIFICATION DU DOCUMENT
   - Nature et contexte
   - Parties impliqu√©es
   - Enjeux principaux

2. ANALYSE JURIDIQUE
   - Fondements juridiques
   - Arguments d√©velopp√©s
   - Points de droit

3. √âVALUATION
   - Forces et faiblesses
   - Risques identifi√©s
   - Recommandations""",

    "Synth√®se contractuelle": """Analysez ce contrat en d√©tail :
- Obligations principales
- Clauses importantes
- Risques et garanties
- Recommandations d'am√©lioration""",

    "Analyse proc√©durale": """Examinez cette proc√©dure :
- Chronologie des √©v√©nements
- Moyens et arguments
- Respect des d√©lais
- Prochaines √©tapes"""
}

# ========================================
# FONCTIONS UTILITAIRES
# ========================================

def load_config():
    """Charge la configuration."""
    if HYBRID_AVAILABLE:
        try:
            app_state["ollama_url"] = load_ollama_config()
            app_state["hybrid_analyzer"] = create_hybrid_analyzer(
                chunk_size=DEFAULT_CONFIG["chunk_size"],
                overlap=DEFAULT_CONFIG["chunk_overlap"]
            )
            return True
        except Exception as e:
            print(f"Erreur chargement config: {e}")
    return False

def save_config(url):
    """Sauvegarde la configuration."""
    if HYBRID_AVAILABLE:
        try:
            message = save_url_on_change(url)
            app_state["ollama_url"] = url
            return message
        except Exception as e:
            return f"Erreur sauvegarde: {str(e)}"
    return f"URL sauvegard√©e: {url}"

def track_activity():
    """Marque une activit√© utilisateur (pour RunPod)."""
    runpod_manager.update_activity()

# ========================================
# FONCTIONS D'ANALYSE
# ========================================

def analyze_hybrid_mode(text1, text2, prompt, model_step1, model_step2, model_step3,
                        provider, temperature, top_p, max_tokens, 
                        chunk_size, chunk_overlap, domain, synthesis_type, enable_step3,
                        ollama_url, runpod_endpoint, runpod_token):
    """Analyse avec le mode hybride 3 √©tapes."""
    
    track_activity()  # Marquer l'activit√©
    
    if not HYBRID_AVAILABLE:
        return fallback_analysis(text1, text2, prompt)
    
    # Pr√©paration du texte
    if text1 and text2:
        full_text = f"=== DOCUMENT 1 ===\n{text1}\n\n=== DOCUMENT 2 ===\n{text2}"
        doc_info = f"2 documents - {len(text1):,} + {len(text2):,} caract√®res"
    elif text1:
        full_text = text1
        doc_info = f"1 document - {len(text1):,} caract√®res"
    elif text2:
        full_text = text2
        doc_info = f"1 document - {len(text2):,} caract√®res"
    else:
        return ("ERREUR: Aucun texte fourni", "", "", "Aucun texte", "")
    
    try:
        # Mise √† jour de l'analyseur
        analyzer = create_hybrid_analyzer(chunk_size=chunk_size, overlap=chunk_overlap)
        
        # Configuration des mod√®les par √©tape
        analyzer.step1_config["preferred_models"] = [model_step1, "mistral:7b", "llama3.1:8b"]
        analyzer.step2_config["preferred_models"] = [model_step2, "mixtral:8x7b", "llama3.1:8b"]
        analyzer.step3_config["preferred_models"] = [model_step3, "llama3.1:8b", "mixtral:8x7b"]
        
        # Analyse hybride
        result = analyzer.analyze_hybrid(
            text=full_text,
            user_prompt=prompt.strip(),
            provider=provider,
            ollama_url=ollama_url,
            runpod_endpoint=runpod_endpoint,
            runpod_token=runpod_token,
            domain=domain if domain != "Aucun" else None,
            enable_step3=enable_step3,
            synthesis_type=synthesis_type
        )
        
        if result["success"]:
            # Formatage du r√©sultat
            formatted_result = analyzer.format_hybrid_result(result, prompt, doc_info)
            
            # Statistiques
            stats1 = f"{len(text1):,} caract√®res" if text1 else "Aucun texte"
            stats2 = f"{len(text2):,} caract√®res" if text2 else "Aucun texte"
            
            # Informations de debug
            debug_info = f"""ANALYSE HYBRIDE EX√âCUT√âE
{'=' * 50}

MODE: Hybride 3 √©tapes
DOMAINE: {domain}
SYNTH√àSE: {synthesis_type if enable_step3 else 'D√©sactiv√©e'}

MOD√àLES UTILIS√âS:
- √âtape 1 (Extraction): {result['step1']['model_used']}
- √âtape 2 (Fusion): {result['step2']['model_used']}
- √âtape 3 (Synth√®se): {result['step3']['model_used'] if result.get('step3') and result['step3']['success'] else 'N/A'}

PERFORMANCE:
- Chunks trait√©s: {result['metadata']['chunks_count']}
- Dur√©e totale: {result['metadata']['processing_time']:.1f}s
- Score efficacit√©: {result['stats']['efficiency_score']}

ARCHITECTURE:
‚úì Extraction rapide ‚Üí {model_step1}
‚úì Fusion intelligente ‚Üí {model_step2}
{'‚úì' if enable_step3 else '‚óã'} Synth√®se premium ‚Üí {model_step3 if enable_step3 else 'D√©sactiv√©e'}"""
            
            # Rapport d√©taill√© (correction de la syntaxe f-string)
            step3_duration = result['step3']['duration'] if result.get('step3') and result['step3']['success'] else 0
            step3_status = "Ex√©cut√©e" if result.get('step3') and result['step3']['success'] else "Non ex√©cut√©e"
            
            analysis_report = f"""RAPPORT D'ANALYSE HYBRIDE

√âtapes ex√©cut√©es:
1. Extraction par chunks: {result['step1']['duration']:.1f}s
2. Fusion et harmonisation: {result['step2']['duration']:.1f}s
3. Synth√®se narrative: {step3_duration:.1f}s ({step3_status})

Optimisation qualit√©/prix r√©ussie"""
            
            return (formatted_result, stats1, stats2, debug_info, analysis_report)
        else:
            error_msg = f"ERREUR ANALYSE HYBRIDE\n\n{result['error']}"
            return (error_msg, "", "", error_msg, "Erreur")
            
    except Exception as e:
        error_msg = f"ERREUR TECHNIQUE\n\n{str(e)}"
        return (error_msg, "", "", error_msg, "Erreur technique")

def analyze_classic_mode(text1, text2, prompt, model, provider, temperature, top_p, max_tokens,
                        ollama_url, runpod_endpoint, runpod_token):
    """Analyse classique directe."""
    
    track_activity()  # Marquer l'activit√©
    
    # Pr√©paration du texte
    if text1 and text2:
        full_text = f"=== DOCUMENT 1 ===\n{text1}\n\n=== DOCUMENT 2 ===\n{text2}"
    else:
        full_text = text1 or text2
    
    if not full_text:
        return ("ERREUR: Aucun texte fourni", "", "", "Aucun texte", "")
    
    try:
        # Analyse directe
        result = ai_call_wrapper(
            text=full_text,
            prompt=prompt.strip(),
            modele=model,
            temperature=temperature,
            top_p=top_p,
            max_tokens_out=max_tokens,
            provider=provider,
            ollama_url_val=ollama_url,
            runpod_endpoint=runpod_endpoint,
            runpod_token=runpod_token
        )
        
        # Formatage
        current_time = datetime.now().strftime("%d/%m/%Y √† %H:%M:%S")
        formatted_result = f"""{'=' * 80}
                    ANALYSE JURIDIQUE CLASSIQUE
{'=' * 80}

HORODATAGE: {current_time}
MOD√àLE: {model}
FOURNISSEUR: {provider}
MODE: Analyse directe
TEXTE: {len(full_text):,} caract√®res

{'-' * 80}
                        PROMPT UTILIS√â
{'-' * 80}

{prompt}

{'-' * 80}
                    R√âSULTAT DE L'ANALYSE
{'-' * 80}

{result}
"""
        
        stats1 = f"{len(text1):,} caract√®res" if text1 else "Aucun texte"
        stats2 = f"{len(text2):,} caract√®res" if text2 else "Aucun texte"
        
        debug_info = f"""ANALYSE CLASSIQUE EX√âCUT√âE

Mode: Direct (sans chunks)
Mod√®le: {model}
Provider: {provider}
Texte: {len(full_text):,} caract√®res"""
        
        return (formatted_result, stats1, stats2, debug_info, "Mode classique")
        
    except Exception as e:
        error_msg = f"ERREUR ANALYSE CLASSIQUE\n\n{str(e)}"
        return (error_msg, "", "", error_msg, "Erreur")

def fallback_analysis(text1, text2, prompt):
    """Analyse de fallback si modules non disponibles."""
    return (
        "‚ö†Ô∏è MODULES D'ANALYSE NON DISPONIBLES\n\nV√©rifiez l'installation des d√©pendances.",
        f"{len(text1) if text1 else 0:,} caract√®res",
        f"{len(text2) if text2 else 0:,} caract√®res",
        "Mode fallback - modules manquants",
        "Erreur: modules non disponibles"
    )

# ========================================
# FONCTIONS CALLBACK
# ========================================

def on_provider_change(provider):
    """Gestion du changement de fournisseur."""
    app_state["current_provider"] = provider
    
    ollama_visible = provider == "Ollama distant"
    runpod_visible = provider == "RunPod.io"
    
    if provider == "Ollama local":
        status = "‚úÖ Ollama local configur√©"
        url_value = ""
        # D√©sactiver l'arr√™t auto si on quitte RunPod
        runpod_manager.disable_auto_stop()
    elif provider == "Ollama distant":
        url_value = app_state["ollama_url"]
        status = f"üåê Ollama distant: {url_value}"
        runpod_manager.disable_auto_stop()
    else:
        url_value = ""
        status = "‚òÅÔ∏è RunPod - Configurez endpoint et token"
    
    return (
        gr.update(visible=ollama_visible, value=url_value),
        gr.update(visible=runpod_visible, value=""),
        gr.update(visible=runpod_visible, value=""),
        gr.update(visible=runpod_visible),  # Auto-stop timeout
        gr.update(visible=runpod_visible),  # Configure auto-stop button
        gr.update(value=status)
    )

def test_connection_real(provider, ollama_url, runpod_endpoint, runpod_token):
    """Test de connexion r√©el."""
    track_activity()
    
    if not HYBRID_AVAILABLE:
        return (
            gr.update(choices=["mistral:7b", "llama3.1:8b"], value="mistral:7b"),
            gr.update(value="‚ö†Ô∏è Mode d√©grad√© - Test simul√©")
        )
    
    try:
        result, models = test_ai_connection(provider, ollama_url, runpod_endpoint, runpod_token)
        
        if models:
            app_state["models_list"] = models
            return (
                gr.update(choices=models, value=models[0]),
                gr.update(value=f"‚úÖ {result} - {len(models)} mod√®les")
            )
        else:
            return (
                gr.update(),
                gr.update(value=f"‚ùå {result}")
            )
    except Exception as e:
        return (
            gr.update(),
            gr.update(value=f"‚ùå Erreur: {str(e)}")
        )

def configure_runpod_autostop(runpod_endpoint, runpod_token, timeout_minutes):
    """Configure l'arr√™t automatique RunPod."""
    if runpod_endpoint and runpod_token:
        message = runpod_manager.configure_auto_stop(runpod_endpoint, runpod_token, timeout_minutes)
        return gr.update(value=f"‚úÖ {message}")
    else:
        return gr.update(value="‚ùå Endpoint et token requis")

def select_prompt(prompt_name):
    """S√©lection d'un prompt."""
    if prompt_name in FALLBACK_PROMPTS:
        prompt_text = FALLBACK_PROMPTS[prompt_name]
        return (
            gr.update(value=prompt_text),
            gr.update(value=f"‚úÖ Prompt '{prompt_name}' charg√©")
        )
    return (
        gr.update(),
        gr.update(value=f"‚ùå Prompt '{prompt_name}' non trouv√©")
    )

def process_file_real(file_path, clean_text=True, anonymize=False):
    """Traitement de fichier r√©el."""
    track_activity()
    
    if not file_path:
        return "Aucun fichier", "0 caract√®res", ""
    
    if not HYBRID_AVAILABLE:
        return "‚ö†Ô∏è Modules non disponibles", "Simulation", "Texte simul√©"
    
    try:
        # CORRECTION: utiliser force_ocr au lieu de force_processing
        message, stats, text, file_type, anon_report = process_file_to_text(
            file_path, clean_text, anonymize, force_ocr=True
        )
        
        if "‚õî" in message:
            return message, "Erreur", ""
        
        return message, stats, text
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}", "Erreur", ""

def clear_all_fields():
    """Nettoie tous les champs."""
    track_activity()
    return (
        "",  # text1
        "",  # text2
        "",  # result
        "",  # stats1
        "",  # stats2
        "",  # debug
        FALLBACK_PROMPTS["Analyse juridique hybride"],  # prompt
        "üßπ Champs nettoy√©s",  # status
        ""   # analysis_report
    )

# ========================================
# INTERFACE GRADIO
# ========================================

def create_hybrid_interface():
    """Cr√©e l'interface Gradio avec mode hybride."""
    
    load_config()
    
    with gr.Blocks(
        title="OCR Juridique - Mode Hybride",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown(f"""
        # üìö OCR Juridique - Mode Hybride v8.2
        
        **Analyse juridique optimis√©e qualit√©/prix** avec architecture 3 √©tapes :
        
        üìÑ **√âtape 1** : Extraction chunks ‚Üí Mistral 7B (rapide, √©conomique)  
        üîÄ **√âtape 2** : Fusion + harmonisation ‚Üí Mixtral 8x7B (contexte large)  
        ‚ú® **√âtape 3** : Synth√®se narrative premium ‚Üí LLaMA3.1 8B (qualit√© r√©dactionnelle)
        
        **√âtat** : {'‚úÖ Mode hybride disponible' if HYBRID_AVAILABLE else '‚ö†Ô∏è Mode d√©grad√©'}
        """)
        
        with gr.Tabs():
            
            # ======= CONFIGURATION =======
            with gr.Tab("üîß Configuration"):
                with gr.Row():
                    with gr.Column():
                        provider = gr.Radio(
                            choices=["Ollama local", "Ollama distant", "RunPod.io"],
                            value="Ollama local",
                            label="Fournisseur IA"
                        )
                        
                        ollama_url = gr.Textbox(
                            label="URL Ollama distant",
                            value=app_state["ollama_url"],
                            visible=False
                        )
                        
                        runpod_endpoint = gr.Textbox(
                            label="Endpoint RunPod",
                            visible=False
                        )
                        
                        runpod_token = gr.Textbox(
                            label="Token RunPod",
                            type="password",
                            visible=False
                        )
                        
                        # Configuration arr√™t automatique RunPod
                        with gr.Group(visible=False) as runpod_autostop_group:
                            gr.Markdown("### ‚è±Ô∏è Arr√™t automatique")
                            autostop_timeout = gr.Slider(
                                minimum=5, maximum=60, value=15, step=5,
                                label="Inactivit√© (minutes)",
                                info="Arr√™t automatique du pod apr√®s inactivit√©"
                            )
                            configure_autostop_btn = gr.Button(
                                "‚öôÔ∏è Configurer arr√™t auto", 
                                variant="secondary"
                            )
                        
                        test_btn = gr.Button("üîç Tester la connexion", variant="primary")
                        
                        status_msg = gr.Textbox(
                            label="Statut",
                            value="Pr√™t" if HYBRID_AVAILABLE else "Mode d√©grad√©",
                            interactive=False
                        )
                    
                    with gr.Column():
                        gr.Markdown("### Mod√®les par √©tape")
                        
                        model_step1 = gr.Dropdown(
                            choices=app_state["models_list"],
                            value="mistral:7b",
                            label="√âtape 1 - Extraction (Mistral 7B recommand√©)",
                            info="Mod√®le rapide pour extraction des chunks"
                        )
                        
                        model_step2 = gr.Dropdown(
                            choices=app_state["models_list"],
                            value="mixtral:8x7b",
                            label="√âtape 2 - Fusion (Mixtral 8x7B recommand√©)",
                            info="Mod√®le √† grand contexte pour fusion"
                        )
                        
                        model_step3 = gr.Dropdown(
                            choices=app_state["models_list"],
                            value="llama3.1:8b",
                            label="√âtape 3 - Synth√®se (LLaMA3.1 8B recommand√©)",
                            info="Mod√®le pour qualit√© r√©dactionnelle"
                        )
                        
                        with gr.Row():
                            temperature = gr.Slider(0, 2, value=0.7, step=0.1, label="Temp√©rature")
                            top_p = gr.Slider(0, 1, value=0.9, step=0.1, label="Top-p")
                            max_tokens = gr.Slider(500, 8000, value=3000, step=500, label="Max tokens")
            
            # ======= DOCUMENTS =======
            with gr.Tab("üìÑ Documents"):
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### Document 1")
                        file1 = gr.File(label="Fichier 1", file_types=[".pdf", ".txt", ".docx"])
                        with gr.Row():
                            clean1 = gr.Checkbox(label="Nettoyer", value=True)
                            anon1 = gr.Checkbox(label="Anonymiser", value=False)
                        text1 = gr.Textbox(label="Texte 1", lines=10)
                        stats1 = gr.Textbox(label="Statistiques 1", interactive=False)
                    
                    with gr.Column():
                        gr.Markdown("### Document 2")
                        file2 = gr.File(label="Fichier 2", file_types=[".pdf", ".txt", ".docx"])
                        with gr.Row():
                            clean2 = gr.Checkbox(label="Nettoyer", value=True)
                            anon2 = gr.Checkbox(label="Anonymiser", value=False)
                        text2 = gr.Textbox(label="Texte 2", lines=10)
                        stats2 = gr.Textbox(label="Statistiques 2", interactive=False)
                
                clear_btn = gr.Button("üóëÔ∏è Nettoyer", variant="stop")
            
            # ======= ANALYSE =======
            with gr.Tab("üîç Analyse"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### Mode d'analyse")
                        analysis_mode = gr.Radio(
                            choices=["Hybride 3 √©tapes", "Classique direct"],
                            value="Hybride 3 √©tapes",
                            label="Mode",
                            info="Hybride = optimisation qualit√©/prix"
                        )
                        
                        # Configuration hybride
                        with gr.Group() as hybrid_config:
                            chunk_size = gr.Slider(
                                1000, 5000, value=3000, step=500,
                                label="Taille chunks", info="Caract√®res par chunk"
                            )
                            chunk_overlap = gr.Slider(
                                0, 500, value=200, step=50,
                                label="Chevauchement", info="Continuit√© entre chunks"
                            )
                            
                            domain = gr.Dropdown(
                                choices=["Aucun"] + list(SUPPORTED_DOMAINS.values()) if HYBRID_AVAILABLE else ["Aucun"],
                                value="Aucun",
                                label="Domaine sp√©cialis√©"
                            )
                            
                            enable_step3 = gr.Checkbox(
                                label="Synth√®se narrative premium (√©tape 3)",
                                value=True,
                                info="Qualit√© r√©dactionnelle optimale"
                            )
                            
                            synthesis_type = gr.Dropdown(
                                choices=list(SYNTHESIS_TYPES.values()) if HYBRID_AVAILABLE else ["Synth√®se ex√©cutive"],
                                value="Synth√®se ex√©cutive",
                                label="Type de synth√®se"
                            )
                        
                        # Prompts pr√©d√©finis
                        gr.Markdown("### Prompts")
                        prompt_selector = gr.Dropdown(
                            choices=list(FALLBACK_PROMPTS.keys()),
                            label="Prompts pr√©d√©finis"
                        )
                        select_prompt_btn = gr.Button("üìù Charger")
                        prompt_status = gr.Textbox(label="Statut", interactive=False)
                    
                    with gr.Column(scale=2):
                        prompt_text = gr.Textbox(
                            label="Prompt d'analyse",
                            lines=10,
                            value=FALLBACK_PROMPTS["Analyse juridique hybride"],
                            placeholder="D√©crivez l'analyse souhait√©e..."
                        )
                        
                        analyze_btn = gr.Button(
                            "üöÄ Lancer l'analyse", 
                            variant="primary", 
                            size="lg"
                        )
            
            # ======= R√âSULTATS =======
            with gr.Tab("üìä R√©sultats"):
                result_text = gr.Textbox(
                    label="R√©sultat de l'analyse",
                    lines=25,
                    show_copy_button=True
                )
                
                with gr.Row():
                    with gr.Column():
                        with gr.Accordion("üìã Rapport d'analyse", open=False):
                            analysis_report = gr.Textbox(
                                label="D√©tails", lines=8, interactive=False
                            )
                    with gr.Column():
                        with gr.Accordion("üîß Debug", open=False):
                            debug_info = gr.Textbox(
                                label="Informations techniques", lines=8, interactive=False
                            )
        
        # ========================================
        # √âV√âNEMENTS
        # ========================================
        
        # Configuration
        provider.change(
            on_provider_change,
            inputs=[provider],
            outputs=[ollama_url, runpod_endpoint, runpod_token, runpod_autostop_group, configure_autostop_btn, status_msg]
        )
        
        test_btn.click(
            test_connection_real,
            inputs=[provider, ollama_url, runpod_endpoint, runpod_token],
            outputs=[model_step1, status_msg]
        )
        
        # Configuration arr√™t automatique RunPod
        configure_autostop_btn.click(
            configure_runpod_autostop,
            inputs=[runpod_endpoint, runpod_token, autostop_timeout],
            outputs=[status_msg]
        )
        
        # Gestion fichiers
        def handle_file1(file):
            if file:
                message, stats, text = process_file_real(file.name, clean1.value, anon1.value)
                return message, stats, text
            return "", "0 caract√®res", ""
        
        def handle_file2(file):
            if file:
                message, stats, text = process_file_real(file.name, clean2.value, anon2.value)
                return stats, text
            return "0 caract√®res", ""
        
        file1.change(handle_file1, inputs=[file1], outputs=[status_msg, stats1, text1])
        file2.change(handle_file2, inputs=[file2], outputs=[stats2, text2])
        
        # Prompts
        select_prompt_btn.click(
            select_prompt,
            inputs=[prompt_selector],
            outputs=[prompt_text, prompt_status]
        )
        
        # Affichage conditionnel config hybride
        def toggle_config(mode):
            return gr.update(visible=(mode == "Hybride 3 √©tapes"))
        
        analysis_mode.change(
            toggle_config,
            inputs=[analysis_mode],
            outputs=[hybrid_config]
        )
        
        # Analyse principale
        def route_analysis(mode, text1, text2, prompt, 
                          model_step1, model_step2, model_step3,
                          provider, temperature, top_p, max_tokens,
                          chunk_size, chunk_overlap, domain, synthesis_type, enable_step3,
                          ollama_url, runpod_endpoint, runpod_token):
            
            if mode == "Hybride 3 √©tapes":
                return analyze_hybrid_mode(
                    text1, text2, prompt, model_step1, model_step2, model_step3,
                    provider, temperature, top_p, max_tokens,
                    chunk_size, chunk_overlap, domain, synthesis_type, enable_step3,
                    ollama_url, runpod_endpoint, runpod_token
                )
            else:
                return analyze_classic_mode(
                    text1, text2, prompt, model_step1, provider, 
                    temperature, top_p, max_tokens,
                    ollama_url, runpod_endpoint, runpod_token
                )
        
        analyze_btn.click(
            route_analysis,
            inputs=[
                analysis_mode, text1, text2, prompt_text,
                model_step1, model_step2, model_step3,
                provider, temperature, top_p, max_tokens,
                chunk_size, chunk_overlap, domain, synthesis_type, enable_step3,
                ollama_url, runpod_endpoint, runpod_token
            ],
            outputs=[result_text, stats1, stats2, debug_info, analysis_report]
        )
        
        # Nettoyage
        clear_btn.click(
            clear_all_fields,
            outputs=[text1, text2, result_text, stats1, stats2, debug_info, 
                    prompt_text, status_msg, analysis_report]
        )
        
        # Sauvegarde URL
        ollama_url.change(save_config, inputs=[ollama_url], outputs=[status_msg])
        
        # Mise √† jour des mod√®les apr√®s test de connexion
        def update_all_models(provider, ollama_url, runpod_endpoint, runpod_token):
            dropdown_result, status_result = test_connection_real(provider, ollama_url, runpod_endpoint, runpod_token)
            return dropdown_result, dropdown_result, dropdown_result, status_result
        
        test_btn.click(
            update_all_models,
            inputs=[provider, ollama_url, runpod_endpoint, runpod_token],
            outputs=[model_step1, model_step2, model_step3, status_msg]
        )
    
    return demo

# ========================================
# FONCTION BUILD_UI
# ========================================

def build_ui():
    """Point d'entr√©e pour main_ocr.py"""
    print("Construction interface hybride...")
    print(f"Mode hybride: {'Disponible' if HYBRID_AVAILABLE else 'Non disponible'}")
    print(f"Gestion RunPod: Arr√™t automatique configur√©")
    return create_hybrid_interface()

# ========================================
# LANCEMENT DIRECT
# ========================================

if __name__ == "__main__":
    print("Interface hybride - Test direct")
    demo = create_hybrid_interface()
    demo.launch(server_port=7860)
